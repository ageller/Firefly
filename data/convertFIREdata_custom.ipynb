{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convertFIREData_custom.ipynb\n",
    "\n",
    "This is an advanced tutorial using FIREreader, be warned!!\n",
    "\n",
    "This notebook can be used on Stampede2, where the halo file and snapshot directories live. You can run this notebook, and host a Firefly server, on Stampede by following the instructions [here](https://github.com/ageller/Firefly/wiki/Hosting-Firefly-on-a-Cluster-Environment). \n",
    "\n",
    "In this notebook, we open the AHF halo files saved on Stampede and offset the snapshot coordinates, as well as convert them to physical units, to put the center of the main halo at our origin. This is optional, since you can always fly within Firefly to a point and set that as your origin, but more convenient (and exact!). \n",
    "\n",
    "We also calculate the radius from the halo center for each particle and update the filter keys so we can interactively filter by radius from within Firefly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataParser import FIREreader\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Reader instance\n",
    "We'll ask for gas and star particles, along with their density, velocity, temperature, and age in gyr as appropriate. The latter two are enabled by Alex Gurvich's openSnapshot utility. You're welcome!\n",
    "\n",
    "Note that a quirk of how Velocity filtering is done (the magnitude of velocity, a vector quantity vs. the quantity itself) we have to pass filterFlag = 0 for Velocity (note also that we never use doMag = 1). This will likely change in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## initialize reader object and choose simulation to run\n",
    "reader = FIREreader(\n",
    "    snapdir = \"/Users/agurvich/research/snaps/m12i_res7100/output\",\n",
    "    snapnum = 600,\n",
    "    JSONdir='m12i_res7100_600',\n",
    "    ptypes = ['PartType0','PartType4'],\n",
    "    UInames = ['Gas','Stars'],\n",
    "    dec_factors = [100,100],\n",
    "    returnKeys = ['Density','Velocities','Temperature','AgeGyr'], ## keys that don't match a particle type are ignored\n",
    "    filterFlags = [1,0,1,1],\n",
    "    colormapFlags = [1,0,1,1],\n",
    "    doMags = [0,0,0,0],\n",
    "    doLogs = [1,0,1,0],\n",
    "    )\n",
    "## could read this from snapshot times\n",
    "current_redshift=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data into the reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ptype PartType0\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.0.hdf5\n",
      "This is a cosmological snapshot... converting to physical units\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.1.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.2.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.3.hdf5\n",
      "Loading ptype PartType4\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.0.hdf5\n",
      "This is a cosmological snapshot... converting to physical units\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.1.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.2.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.3.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Particle Group of Gas\n",
       " Contains 56897231 (568972 after dec) particles and 3 arrays,\n",
       " Particle Group of Stars\n",
       " Contains 13728304 (137283 after dec) particles and 2 arrays]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.loadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the AHF Halo file and extract the halo center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_AHF(directory,snapnum,current_redshift,hubble = 0.702):\n",
    "        path = os.path.join(directory,'../halo/ahf/halo_00000_smooth.dat')\n",
    "        \n",
    "        ## find column numbers without having to count\n",
    "        names_to_read = ['snum','Xc','Yc','Zc','Rvir','v_esc','Rstar0.5']\n",
    "        \n",
    "        ## load the first line of the datafile\n",
    "        names = list(np.genfromtxt(path,skip_header=0,max_rows = 1,dtype=str))\n",
    "        cols = []\n",
    "\n",
    "        ## find the column each name appears in\n",
    "        for name in names_to_read:\n",
    "            cols+=[names.index(name)]\n",
    "\n",
    "        ## load the rest of the file\n",
    "        sns,xs,ys,zs, rvirs, vescs, rstar_halfs = np.genfromtxt(\n",
    "            path,delimiter='\\t',usecols=cols,unpack=1,skip_header=1)\n",
    "\n",
    "        ## which row do I care about? make an index array\n",
    "        index = sns==snapnum\n",
    "        if np.sum(index)==0:\n",
    "            ## snapnum is not in this halo file\n",
    "            raise IOError\n",
    "            \n",
    "        ## presumably in comoving kpc/h \n",
    "        halo_center = np.array([xs[index],ys[index],zs[index]])/hubble*(1/(1+current_redshift))\n",
    "        halo_center = halo_center.reshape(3,)\n",
    "\n",
    "        ## convert other quantities one might care about from comoving kpc to pkpc\n",
    "        rvir = rvirs[index][0]/hubble/(1+current_redshift)\n",
    "        vesc = vescs[index][0]\n",
    "        rstar_half = rstar_halfs[index][0]/hubble/(1+current_redshift)\n",
    "        return halo_center, rvir, vesc, rstar_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 41875.75818899  44122.37307211  46257.47577379] 273.803418803\n"
     ]
    }
   ],
   "source": [
    "## open the halo file and find the center\n",
    "halo_center,rvir,vesc,rstar_half = load_AHF(reader.snapdir,reader.snapnum,current_redshift)\n",
    "print halo_center,rvir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune the particleGroups\n",
    "We can change the default color of each particle group and adjust the units/offsets for various quantities. For instance, here, we'll \n",
    "* change the density into physical units\n",
    "* calculate the galactocentric radius and make them filterable\n",
    "* change the default color\n",
    "* change the default size for both particle groups\n",
    "* offset the coordinates by the halo's center of mass so that we can center our view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = [\n",
    "    [1,0,0,1],## gas is red\n",
    "    [0,0,1,1] ## stars are blue\n",
    "]\n",
    "\n",
    "# Code mass -> g , (code length)^-3 -> cm^-3 , g -> nHydrogen\n",
    "DENSITYFACT=2e43*(3.086e21)**-3/(1.67e-24)\n",
    "\n",
    "for i,particleGroup in enumerate(reader.particleGroups):\n",
    "    particleGroup.coordinates-=halo_center ## both are already in physical units\n",
    "\n",
    "    ## now calculate the galactocentric radii and track them\n",
    "    radii = np.sum(particleGroup.coordinates**2,axis=1)**0.5\n",
    "    particleGroup.trackArray('Radius',radii,filter_flag=1)\n",
    "\n",
    "    ## let's convert the density into physical units\n",
    "    if 'log10Density' in particleGroup.tracked_names:\n",
    "        ## gas is the first particle group\n",
    "        particleGroup['log10Density'] = particleGroup['log10Density']+np.log10(DENSITYFACT)\n",
    "\n",
    "    ## change some of the options like the size of the particles and their color\n",
    "    reader.options['sizeMult'][particleGroup.UIname]=0.3 ## set the particle size\n",
    "    reader.options['color'][particleGroup.UIname]=colors[i] ## set the particle colors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reopening the Snapshot File\n",
    "You might have to reopen the snapshot files to get at arrays that weren't opened in returnKeys (let's say because you didn't want to keep track of a mass array and just inflate the size of your `.json` files). You can do this by using the `particleGroup.filenames_opened` attribute that the `FIREreader` class tracks for each particleGroup. \n",
    "\n",
    "As an example of this, let's remove the center of mass velocity from both particle group's velocities so that velocity vectors are accurate. To do that we will need to \n",
    "* Open each of the snapshots and extract the masses\n",
    "* find the stars near to the main halo\n",
    "* compute the center of mass velocity\n",
    "* subtract the center of mass velocity from each of the `Velocities` `tracked_array`s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert particleGroup.UIname == 'Stars'\n",
    "star_masses = []\n",
    "## open each of the files and extract the masses\n",
    "for filename in particleGroup.filenames_opened:\n",
    "    with h5py.File(filename,'r') as handle:\n",
    "        star_masses = np.append(star_masses,handle['PartType4/Masses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-49.62116791,  75.18697612,  95.4050726 ]), 'kms')\n"
     ]
    }
   ],
   "source": [
    "## find the nearby star particles\n",
    "near_star_indices = particleGroup['Radius'] < 50 ## kpc\n",
    "## calculate vcom\n",
    "near_star_vcom = (\n",
    "    np.sum(star_masses[near_star_indices][:,None]\n",
    "    *particleGroup['Velocities'][near_star_indices],axis=0)\n",
    "    /np.sum(star_masses[near_star_indices])\n",
    ")\n",
    "\n",
    "print(near_star_vcom,'kms')\n",
    "\n",
    "## now let's remove it from the particle velocities\n",
    "for particleGroup in reader.particleGroups:\n",
    "    particleGroup['Velocities']-=near_star_vcom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output our Reader instance's info to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputting Particle Group of Gas\n",
      "Contains 56897231 (568972 after dec) particles and 4 arrays\n",
      "\n",
      "['log10Density', 'Velocities', 'log10Temperature', 'Radius'] [1, 0, 1, 1]\n",
      "outputting Particle Group of Stars\n",
      "Contains 13728304 (137283 after dec) particles and 3 arrays\n",
      "\n",
      "['Velocities', 'AgeGyr', 'Radius'] [0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "reader.dumpToJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
