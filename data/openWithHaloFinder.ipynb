{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openWithHaloFinder.ipynb\n",
    "\n",
    "This is an advanced tutorial using FIREreader, be warned!!\n",
    "\n",
    "This notebook is best used on Stampede2, where the halo file and snapshot directories live. You can run this notebook, and host a Firefly server, on Stampede by following the instructions [here](https://github.com/ageller/Firefly/wiki/Hosting-Firefly-on-a-Cluster-Environment). \n",
    "\n",
    "In this notebook, we open the AHF halo files saved on Stampede and offset the snapshot coordinates, as well as convert them to physical units, to put the center of the main halo at our origin. This is optional, since you can always fly within Firefly to a point and set that as your origin, but more convenient (and exact!). \n",
    "\n",
    "We also calculate the radius from the halo center for each particle and update the filter keys so we can interactively filter by radius from within Firefly. \n",
    "\n",
    "#### Importantly, we do **not** call the `reader.run()` method, which would not give us the flexibility required to change our units/calculate the radii & temperature before we output to JSON. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from FIREreader import FIREreader\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize reader object and choose simulation to run\n",
    "reader = FIREreader()\n",
    "reader.directory = \"/Users/agurvich/research/snaps/m12i_res7100/output\"\n",
    "reader.snapnum = 600\n",
    "## could read this from snapshot times\n",
    "current_redshift=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the AHF Halo file and extract the halo center and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_AHF(directory,snapnum,current_redshift,hubble = 0.702):\n",
    "        path = os.path.join(directory,'../halo/ahf/halo_00000_smooth.dat')\n",
    "        \n",
    "        ## find column numbers without having to count\n",
    "        names_to_read = ['snum','Xc','Yc','Zc','Rvir','v_esc','Rstar0.5']\n",
    "        \n",
    "        ## load the first line of the datafile\n",
    "        names = list(np.genfromtxt(path,skip_header=0,max_rows = 1,dtype=str))\n",
    "        cols = []\n",
    "\n",
    "        ## find the column each name appears in\n",
    "        for name in names_to_read:\n",
    "            cols+=[names.index(name)]\n",
    "\n",
    "        ## load the rest of the file\n",
    "        sns,xs,ys,zs, rvirs, vescs, rstar_halfs = np.genfromtxt(\n",
    "            path,delimiter='\\t',usecols=cols,unpack=1,skip_header=1)\n",
    "\n",
    "        ## which row do I care about? make an index array\n",
    "        index = sns==snapnum\n",
    "        if np.sum(index)==0:\n",
    "            ## snapnum is not in this halo file\n",
    "            raise IOError\n",
    "            \n",
    "        ## presumably in comoving kpc/h \n",
    "        halo_center = np.array([xs[index],ys[index],zs[index]])/hubble*(1/(1+current_redshift))\n",
    "        halo_center = halo_center.reshape(3,)\n",
    "\n",
    "        ## convert other quantities one might care about from comoving kpc to pkpc\n",
    "        rvir = rvirs[index][0]/hubble/(1+current_redshift)\n",
    "        vesc = vescs[index][0]\n",
    "        rstar_half = rstar_halfs[index][0]/hubble/(1+current_redshift)\n",
    "        return halo_center, rvir, vesc, rstar_half\n",
    "    \n",
    "def getTemperature(U_code,y_helium,ElectronAbundance):\n",
    "    \"\"\"U_codes = res['u']\n",
    "        y_heliums = res['z'][:,1]\n",
    "        ElectronAbundance=res['ne']\"\"\"\n",
    "    U_cgs = U_code*1e10\n",
    "    gamma=5/3.\n",
    "    kB=1.38e-16 #erg /K\n",
    "    m_proton=1.67e-24 # g\n",
    "    mu = (1.0 + 4*y_helium) / (1+y_helium+ElectronAbundance) \n",
    "    mean_molecular_weight=mu*m_proton\n",
    "    return mean_molecular_weight * (gamma-1) * U_cgs / kB # kelvin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 41875.75818899  44122.37307211  46257.47577379] 273.803418803\n"
     ]
    }
   ],
   "source": [
    "## open the halo file and find the center\n",
    "halo_center,rvir,vesc,rstar_half = load_AHF(reader.directory,reader.snapnum,current_redshift)\n",
    "print halo_center,rvir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the reader configuration and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## decide which part types to save to JSON\n",
    "reader.returnParts = ['PartType0', 'PartType4']\n",
    "\n",
    "## choose the names the particle types will get in the UI\n",
    "reader.names = {'PartType0':'Gas', \n",
    "                  'PartType1':'HRDM', \n",
    "                  'PartType2':'LRDM', \n",
    "                  'PartType4':'Stars' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the defaults; this must be run first if you want to change the defaults below\n",
    "reader.defineDefaults()\n",
    "\n",
    "## by what factor should you sub-sample the data (e.g. array[::decimate])\n",
    "decimate = [100., 1000.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.0.hdf5\n",
      "This is a cosmological snapshot... converting to physical units\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.1.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.2.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.3.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.0.hdf5\n",
      "This is a cosmological snapshot... converting to physical units\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.1.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.2.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.3.hdf5\n",
      "PartType4 has no Density\n"
     ]
    }
   ],
   "source": [
    "## load in the data from hdf5 files and put it into reader.partsDict\n",
    "for i,p in enumerate(reader.returnParts):\n",
    "    reader.decimate[p] = decimate[i]\n",
    "    reader.returnKeys[p] = ['Coordinates', 'Density','Velocities']\n",
    "    #Note: you should only try to filter on scalar values (like density).  \n",
    "    #The magnitude of the Velocities are calculated in Firefly, and you will automatically be allowed to filter on it\n",
    "    reader.addFilter[p] = [False, True, False]\n",
    "    ## tell it to do the log of density when filtering\n",
    "    reader.dolog[p] = [False, True, False]\n",
    "    \n",
    "    \n",
    "    #NOTE: all dictionaries in the \"options\" reference the swapped names (i.e., reader.names) you define above.  \n",
    "    #If you don't define reader.names, then you can use the default keys from the hdf5 files \n",
    "    #(but then you will see those hdf5 names in the Firefly GUI)\n",
    "    pp = reader.names[p]\n",
    "    ## set the initial size of the particles when the interface loads\n",
    "    reader.options['sizeMult'][pp] = 0.3\n",
    "    \n",
    "## set the default colors when the interface loads\n",
    "reader.options['color'] = {'Gas':  [1., 0., 0., 1.],  \n",
    "                           'HRDM': [1., 1., 0., 0.1],  \n",
    "                           'LRDM': [1., 1., 0., 0.1],  \n",
    "                           'Stars':[0., 0., 1., 0.1]} \n",
    "\n",
    "## set the camera center to be at the origin (defaults to np.mean(Coordinates) otherwise)\n",
    "##     later on we subtract out halo_center from coordinates but could instead make this halo_center\n",
    "reader.options['center'] = np.array([0., 0., 0.])\n",
    "\n",
    "## initialize filter flags and options\n",
    "reader.defineFilterKeys()\n",
    "\n",
    "## load in return keys from snapshot\n",
    "filenames_opened = reader.populate_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate the galactocentric radius, offset the coordinates by it while we're at it, then add the array to Firefly using the `addtodict` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubble=.702\n",
    "\n",
    "## while we're at it, let's just shift all the coordinates relative to the main halo center\n",
    "reader.partsDict['PartType0']['Coordinates']=reader.partsDict['PartType0']['Coordinates']-halo_center ## both already in physical coordinates\n",
    "reader.partsDict['PartType4']['Coordinates']=reader.partsDict['PartType4']['Coordinates']-halo_center ## both already in physical coordinates\n",
    "\n",
    "## calculate the radius from the halo center\n",
    "gas_radii = np.sum(reader.partsDict['PartType0']['Coordinates']**2,axis=1)**0.5\n",
    "star_radii = np.sum(reader.partsDict['PartType4']['Coordinates']**2,axis=1)**0.5\n",
    "\n",
    "## add new radius array to the dictionary using addtodict method\n",
    "reader.addtodict(reader.partsDict,None,'PartType0','Radius',0,0,vals=gas_radii, filterFlag = True)\n",
    "reader.addtodict(reader.partsDict,None,'PartType4','Radius',0,0,vals=star_radii, filterFlag = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's convert the density to physical units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code mass -> g , (code length)^-3 -> cm^-3 , g -> nHydrogen\n",
    "DENSITYFACT=2e43*(3.086e21)**-3/(1.67e-24)\n",
    "reader.partsDict['PartType0']['log10Density'] = reader.partsDict['PartType0']['log10Density']+np.log10(DENSITYFACT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's load necessary supplemental data to calculate the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.0.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.1.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.2.hdf5\n",
      "/Users/agurvich/research/snaps/m12i_res7100/output/snapdir_600/snapshot_600.3.hdf5\n"
     ]
    }
   ],
   "source": [
    "## add temperature as a filtered quantity within the parts dict, but only for gas\n",
    "all_gas_temperature = np.array([])\n",
    "all_star_masses = np.array([])\n",
    "for fname in reader.loadedHDF5Files:\n",
    "    print fname\n",
    "    with h5py.File(fname,'r') as handle:\n",
    "        ## load necessary arrays to calculate temperature\n",
    "        gas_group = handle['PartType0']\n",
    "        InternalEnergy = np.array(gas_group['InternalEnergy'])\n",
    "        ElectronAbundance = np.array(gas_group['ElectronAbundance'])\n",
    "        Metallicity = np.array(gas_group['Metallicity'])\n",
    "        \n",
    "        ## calculate the temperature and append it to total array\n",
    "        all_gas_temperature=np.append(\n",
    "            all_gas_temperature,\n",
    "            getTemperature(\n",
    "                InternalEnergy,\n",
    "                Metallicity[:,1],\n",
    "                ElectronAbundance)\n",
    "        )\n",
    "        \n",
    "        ## save stellar masses for vcom below\n",
    "        all_star_masses=np.append(\n",
    "            all_star_masses,\n",
    "            np.array(handle['PartType4/Masses'])\n",
    "        )\n",
    "    \n",
    "## track the Temperature array, do the log, and add it to be filtered\n",
    "reader.addtodict(reader.partsDict,None,'PartType0','Temperature',sendlog = 1, sendmag = 0,vals = all_gas_temperature, filterFlag = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's remove halo \"CoM\" velocity from velocities so that velocity vectors are accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-51.02232016,  74.50281519,  96.03350012]), 'kms')\n"
     ]
    }
   ],
   "source": [
    "## find the nearby stars\n",
    "near_star_indices = star_radii < rstar_half\n",
    "\n",
    "## calculate vcom\n",
    "near_star_vcom = (\n",
    "    np.sum(all_star_masses[near_star_indices][:,None]\n",
    "    *reader.partsDict['PartType4']['Velocities'][near_star_indices],axis=0)\n",
    "    /np.sum(all_star_masses[near_star_indices])\n",
    ")\n",
    "\n",
    "print(near_star_vcom,'kms')\n",
    "\n",
    "## now let's remove it from the particle velocities\n",
    "reader.partsDict['PartType4']['Velocities']-=near_star_vcom\n",
    "reader.partsDict['PartType0']['Velocities']-=near_star_vcom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decimating and shuffling ...\n",
      "decimating and shuffling ...\n",
      "('dataDir', None)\n",
      "writing JSON files ...\n",
      "Gas\n",
      "Stars\n",
      "/Users/agurvich/research/repos/Firefly/data/m12i_res7100_600/FIREdataOptions.json\n"
     ]
    }
   ],
   "source": [
    "## finish up, let's shuffle + decimate, add the GUI friendly names, and create our final JSON!\n",
    "reader.shuffle_dict()\n",
    "reader.swap_dict_names()\n",
    "reader.createJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c39c8f7fadc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateJSON\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reader' is not defined"
     ]
    }
   ],
   "source": [
    "reader.createJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
