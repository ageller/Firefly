{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openWithHaloFinder.ipynb\n",
    "\n",
    "This is an advanced tutorial using FIREreader, be warned!!\n",
    "\n",
    "This notebook is best used on Stampede2, where the halo file and snapshot directories live. You can run this notebook, and host a Firefly server, on Stampede by following the instructions [here](https://github.com/ageller/Firefly/wiki/Hosting-Firefly-on-a-Cluster-Environment). \n",
    "\n",
    "In this notebook, we open the AHF halo files saved on Stampede and offset the snapshot coordinates, as well as convert them to physical units, to put the center of the main halo at our origin. This is optional, since you can always fly within Firefly to a point and set that as your origin, but more convenient (and exact!). \n",
    "\n",
    "We also calculate the radius from the halo center for each particle and update the filter keys so we can interactively filter by radius from within Firefly. \n",
    "\n",
    "#### Importantly, we do **not** call the `reader.run()` method, which would not give us the flexibility required to change our units/calculate the radii before we output to JSON. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from FIREreader import FIREreader\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the FIRE Reader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = FIREreader()\n",
    "reader.directory = \"/scratch/projects/xsede/GalaxiesOnFIRE/core/m12i_res7100/output\"\n",
    "reader.snapnum = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the AHF Halo file and extract the halo center and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_AHF(directory,snapnum,current_redshift,hubble = 0.702):\n",
    "        path = os.path.join(directory,'../halo/ahf/halo_00000_smooth.dat')\n",
    "        \n",
    "        ## find column numbers without having to count\n",
    "        names_to_read = ['snum','Xc','Yc','Zc','Rvir','v_esc','Rstar0.5']\n",
    "        \n",
    "        ## load the first line of the datafile\n",
    "        names = list(np.genfromtxt(path,skip_header=0,max_rows = 1,dtype=str))\n",
    "        cols = []\n",
    "\n",
    "        ## find the column each name appears in\n",
    "        for name in names_to_read:\n",
    "            cols+=[names.index(name)]\n",
    "\n",
    "        ## load the rest of the file\n",
    "        sns,xs,ys,zs, rvirs, vescs, rstar_halfs = np.genfromtxt(\n",
    "            path,delimiter='\\t',usecols=cols,unpack=1,skip_header=1)\n",
    "\n",
    "        ## which row do I care about? make an index array\n",
    "        index = sns==snapnum\n",
    "        if np.sum(index)==0:\n",
    "            ## snapnum is not in this halo file\n",
    "            raise IOError\n",
    "            \n",
    "        ## presumably in comoving kpc/h \n",
    "        halo_center = np.array([xs[index],ys[index],zs[index]])/hubble*(1/(1+current_redshift))\n",
    "        halo_center = halo_center.reshape(3,)\n",
    "\n",
    "        ## convert other quantities one might care about from comoving kpc to pkpc\n",
    "        rvir = rvirs[index][0]/hubble/(1+current_redshift)\n",
    "        vesc = vescs[index][0]\n",
    "        rstar_half = rstar_halfs[index][0]/hubble/(1+current_redshift)\n",
    "        return halo_center, rvir, vesc, rstar_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 41875.75818899  44122.37307211  46257.47577379] 273.803418803\n"
     ]
    }
   ],
   "source": [
    "## redshift is hard-coded in now, but you could imagine looking it up in snapshot-times.txt! :]\n",
    "halo_center,rvir,vesc,rstar_half = load_AHF(reader.directory,reader.snapnum,current_redshift=0)\n",
    "print halo_center,rvir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the reader configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## decide which part types to save to JSON\n",
    "reader.returnParts = ['PartType0', 'PartType4']\n",
    "\n",
    "## choose the names the particle types will get in the UI\n",
    "reader.names = {'PartType0':'Gas', \n",
    "                  'PartType1':'HRDM', \n",
    "                  'PartType2':'LRDM', \n",
    "                  'PartType4':'Stars' }\n",
    "\n",
    "#define the defaults; this must be run first if you want to change the defaults below\n",
    "reader.defineDefaults()\n",
    "\n",
    "## by what factor should you sub-sample the data (e.g. array[::decimate])\n",
    "decimate = [100., 1000.]\n",
    "\n",
    "## load in the data from hdf5 files and put it into reader.partsDict\n",
    "for i,p in enumerate(reader.returnParts):\n",
    "    reader.decimate[p] = decimate[i]\n",
    "    reader.returnKeys[p] = ['Coordinates', 'Density','Velocities']\n",
    "    #Note: you should only try to filter on scalar values (like density).  \n",
    "    #The magnitude of the Velocities are calculated in Firefly, and you will automatically be allowed to filter on it\n",
    "    reader.addFilter[p] = [False, True, False]\n",
    "    reader.dolog[p] = [False, True, False]\n",
    "\n",
    "    #NOTE: all dictionaries in the \"options\" reference the swapped names (i.e., reader.names) you define above.  \n",
    "    #If you don't define reader.names, then you can use the default keys from the hdf5 files \n",
    "    #(but then you will see those hdf5 names in the Firefly GUI)\n",
    "    pp = reader.names[p]\n",
    "    ## set the initial size of the particles when the interface loads\n",
    "    reader.options['sizeMult'][pp] = 0.3\n",
    "\n",
    "## set the default colors when the interface loads\n",
    "reader.options['color'] = {'Gas':  [1., 0., 0., 1.],  \n",
    "                           'HRDM': [1., 1., 0., 0.1],  \n",
    "                           'LRDM': [1., 1., 0., 0.1],  \n",
    "                           'Stars':[0., 0., 1., 0.1]} \n",
    "\n",
    "## set the camera center to be at the origin (defaults to np.mean(Coordinates) otherwise)\n",
    "reader.options['center'] = np.array([0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run defineFilterKeys to add filters for whatever we pull out of the snapshot\n",
    "reader.defineFilterKeys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and filter by quantities derived from the snapshot (but not in it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Temperature filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemperature(U_code,y_helium,ElectronAbundance):\n",
    "    \"\"\"U_codes = res['u']\n",
    "        y_heliums = res['z'][:,1]\n",
    "        ElectronAbundance=res['ne']\"\"\"\n",
    "    U_cgs = U_code*1e10\n",
    "    gamma=5/3.\n",
    "    kB=1.38e-16 #erg /K\n",
    "    m_proton=1.67e-24 # g\n",
    "    mu = (1.0 + 4*y_helium) / (1+y_helium+ElectronAbundance) \n",
    "    mean_molecular_weight=mu*m_proton\n",
    "    return mean_molecular_weight * (gamma-1) * U_cgs / kB # kelvin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PartType4': [False, True, False], 'PartType0': [False, True, False, False, False, False]}\n",
      "{'PartType4': array([False, False, False], dtype=bool), 'PartType0': array([False, False, False, False, False, False], dtype=bool)}\n"
     ]
    }
   ],
   "source": [
    "## have to setup dolog/domags for the ElectronAbundance/Metallicity/InternalEnergy arrays \n",
    "##     even if I want to remove them from the partsDict before casting to JSON\n",
    "reader.dolog['PartType0']+=[False,False,False]\n",
    "reader.domag['PartType0']=np.append(reader.domag['PartType0'],[False,False,False])\n",
    "print reader.dolog\n",
    "print reader.domag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PartType4': ['Coordinates', 'Density', 'Velocities'], 'PartType0': ['Coordinates', 'Density', 'Velocities', 'InternalEnergy', 'ElectronAbundance', 'Metallicity']}\n",
      "{'PartType4': ['log10Density'], 'PartType0': ['log10Density', 'log10Temperature']}\n"
     ]
    }
   ],
   "source": [
    "## tell FIREreader to open the necessary arrays from the hdf5 file\n",
    "reader.returnKeys['PartType0']+=['InternalEnergy','ElectronAbundance','Metallicity']\n",
    "## add temperature as a filtered quantity within the parts dict, but only for gas\n",
    "reader.filterKeys['PartType0']+=['log10Temperature']\n",
    "reader.options['filterVals']['Gas']['log10Temperature']=None\n",
    "print reader.returnKeys\n",
    "print reader.filterKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Radius filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PartType4': ['log10Density', 'Radius'], 'PartType0': ['log10Density', 'log10Temperature', 'Radius']}\n"
     ]
    }
   ],
   "source": [
    "## add radius as a filtered quantity within the parts dict\n",
    "reader.filterKeys['PartType4']+=['Radius']\n",
    "reader.options['filterVals']['Stars']['Radius']=None\n",
    "\n",
    "## do the same for the gas particles\n",
    "reader.filterKeys['PartType0']+=['Radius']\n",
    "reader.options['filterVals']['Gas']['Radius']=None\n",
    "print reader.filterKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and decimate the snapshot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/projects/xsede/GalaxiesOnFIRE/core/m12i_res7100/output/snapdir_600/snapshot_600.0.hdf5\n",
      "/scratch/projects/xsede/GalaxiesOnFIRE/core/m12i_res7100/output/snapdir_600/snapshot_600.3.hdf5\n",
      "/scratch/projects/xsede/GalaxiesOnFIRE/core/m12i_res7100/output/snapdir_600/snapshot_600.2.hdf5\n",
      "/scratch/projects/xsede/GalaxiesOnFIRE/core/m12i_res7100/output/snapdir_600/snapshot_600.1.hdf5\n",
      "decimating and shuffling ...\n",
      "decimating and shuffling ...\n"
     ]
    }
   ],
   "source": [
    "##load the snapshot data into reader.partsDict\n",
    "reader.populate_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['log10Density', 'log10Temperature', 'Radius']\n",
      "['log10Density', 'Radius']\n"
     ]
    }
   ],
   "source": [
    "## confirm that firefly knows it should be able to filter on Radius, and on temperature for gas\n",
    "print reader.partsDict['Gas']['filterKeys']\n",
    "print reader.partsDict['Stars']['filterKeys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's actually calculate the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doSPHrad', 'InternalEnergy', 'Velocities', 'Coordinates', 'filterKeys', 'Metallicity', 'ElectronAbundance', 'log10Density']\n"
     ]
    }
   ],
   "source": [
    "print reader.partsDict['Gas'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doSPHrad', 'InternalEnergy', 'Velocities', 'log10Temperature', 'Coordinates', 'filterKeys', 'Metallicity', 'ElectronAbundance', 'log10Density']\n",
      "['doSPHrad', 'Velocities', 'log10Temperature', 'Coordinates', 'filterKeys', 'log10Density']\n"
     ]
    }
   ],
   "source": [
    "## calculate the gas temperature\n",
    "partsDict = reader.partsDict['Gas']\n",
    "gas_temperature=getTemperature(partsDict['InternalEnergy'],partsDict['Metallicity'][:,1],partsDict['ElectronAbundance'])\n",
    "\n",
    "## add it to the partsDict, but let's take the log because that's more helpful\n",
    "partsDict['log10Temperature']=np.log10(gas_temperature)\n",
    "print reader.partsDict['Gas'].keys()\n",
    "\n",
    "## let's remove the internal energy, electron abundance, and metallicity since we don't want it and it'll increase the JSON filesize\n",
    "partsDict.pop('InternalEnergy')\n",
    "partsDict.pop('Metallicity')\n",
    "partsDict.pop('ElectronAbundance')\n",
    "print partsDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coordinates', 'Density', 'Velocities', 'Temperature']\n",
      "[False, True, False, True]\n"
     ]
    }
   ],
   "source": [
    "## update the return keys since those arrays no longer exist... \n",
    "reader.returnKeys['PartType0']=reader.returnKeys['PartType0'][:-3]+['Temperature'] ## <--- not log10 because this \"should\" match hdf5 keys\n",
    "print reader.returnKeys['PartType0']\n",
    "\n",
    "## and update the dolog/domag... -2 because we want to save a spot for temperature\n",
    "reader.domag['PartType0']=reader.domag['PartType0'][:-2]\n",
    "reader.dolog['PartType0']=reader.dolog['PartType0'][:-2]\n",
    "\n",
    "## and actually, we *would* like to take the log of temperature, so let's set temperature's do log to True\n",
    "reader.dolog['PartType0'][-1]=True\n",
    "## let's ensure our dolog is matching log10___ and that we didn't mess anything up \n",
    "print reader.dolog['PartType0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's actually calculate the radius, offset the coordinates while we're at it, and convert to physical units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubble=.702\n",
    "current_redshift=0\n",
    "## calculate the radius from the halo center\n",
    "gas_radii = np.sum((reader.partsDict['Gas']['Coordinates']/hubble/(1+current_redshift)-halo_center)**2,axis=1)**0.5\n",
    "star_radii = np.sum((reader.partsDict['Stars']['Coordinates']/hubble/(1+current_redshift)-halo_center)**2,axis=1)**0.5\n",
    "\n",
    "## while we're at it, let's just shift all the coordinates relative to the main halo center\n",
    "reader.partsDict['Gas']['Coordinates']=reader.partsDict['Gas']['Coordinates']/hubble/(1+current_redshift)-halo_center\n",
    "reader.partsDict['Stars']['Coordinates']=reader.partsDict['Stars']['Coordinates']/hubble/(1+current_redshift)-halo_center\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While we're here, let's remove the nearby star particles' CoM velocity from the Gas and Star particles' velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-52.30682755  75.72032928  97.58249664] kms\n"
     ]
    }
   ],
   "source": [
    "near_star_indices = star_radii < rstar_half\n",
    "\n",
    "## let's not load masses just to delete them to make this calculation... the mean is close enough\n",
    "near_star_vcom = np.mean(reader.partsDict['Stars']['Velocities'][near_star_indices],axis=0)\n",
    "print near_star_vcom,'kms'\n",
    "\n",
    "## now let's remove it from the particle velocities\n",
    "reader.partsDict['Stars']['Velocities']-=near_star_vcom\n",
    "reader.partsDict['Gas']['Velocities']-=near_star_vcom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doSPHrad', 'Velocities', 'log10Temperature', 'Coordinates', 'filterKeys', 'Radius', 'log10Density']\n",
      "['filterKeys', 'Radius', 'Velocities', 'doSPHrad', 'Coordinates']\n"
     ]
    }
   ],
   "source": [
    "## let's add the newly computed radii to the partsDict\n",
    "reader.partsDict['Gas']['Radius']=gas_radii\n",
    "reader.partsDict['Stars']['Radius']=star_radii\n",
    "print reader.partsDict['Gas'].keys()\n",
    "print reader.partsDict['Stars'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise for the reader: loop through each of the particle arrays in each partsDict[\\*] and filter using numpy index arrays \n",
    "so that you only put the stuff w/i the virial radius into the JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the JSON file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing JSON files ...\n",
      "Gas\n",
      "Stars\n",
      "snapdir_600/FIREdataOptions.json\n"
     ]
    }
   ],
   "source": [
    "reader.createJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
