{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openWithHaloFinder.ipynb\n",
    "\n",
    "This is an advanced tutorial using FIREreader, be warned!!\n",
    "\n",
    "This notebook is best used on Stampede2, where the halo file and snapshot directories live. You can run this notebook, and host a Firefly server, on Stampede by following the instructions [here](https://github.com/ageller/Firefly/wiki/Hosting-Firefly-on-a-Cluster-Environment). \n",
    "\n",
    "In this notebook, we open the AHF halo files saved on Stampede and offset the snapshot coordinates, as well as convert them to physical units, to put the center of the main halo at our origin. This is optional, since you can always fly within Firefly to a point and set that as your origin, but more convenient (and exact!). \n",
    "\n",
    "We also calculate the radius from the halo center for each particle and update the filter keys so we can interactively filter by radius from within Firefly. \n",
    "\n",
    "#### Importantly, we do **not** call the `reader.run()` method, which would not give us the flexibility required to change our units/calculate the radii & temperature before we output to JSON. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from FIREreader import FIREreader\n",
    "from snapshot_utils import openSnapshot\n",
    "from snapshot_utils import getTemperature\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## initialize reader object and choose simulation to run\n",
    "reader = FIREreader()\n",
    "reader.directory = r\"\\Users\\shife\\OneDrive\\CIERA_REU\\Snapshots\\AlexRichingsCHIMES\\output\"\n",
    "reader.snapnum = 500\n",
    "## could read this from snapshot times\n",
    "current_redshift=0\n",
    "reader.writeStartup = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the AHF Halo file and extract the halo center and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTemperature(U_code,mu):\n",
    "    \"\"\"U_codes = res['u']\n",
    "        mu = res['u']\"\"\"\n",
    "    U_cgs = U_code*1e10\n",
    "    gamma=5/3.\n",
    "    kB=1.38e-16 #erg /K\n",
    "    m_proton=1.67e-24 # g \n",
    "    mean_molecular_weight=mu*m_proton\n",
    "    return mean_molecular_weight * (gamma-1) * U_cgs / kB # kelvin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the reader configuration and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## decide which part types to save to JSON\n",
    "reader.returnParts = ['PartType0', 'PartType4']\n",
    "\n",
    "## choose the names the particle types will get in the UI\n",
    "reader.names = {'PartType0':'Gas', \n",
    "                  'PartType4':'Stars' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the defaults; this must be run first if you want to change the defaults below\n",
    "reader.defineDefaults()\n",
    "\n",
    "## by what factor should you sub-sample the data (e.g. array[::decimate])\n",
    "decimate = [10., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Users\\shife\\OneDrive\\CIERA_REU\\Snapshots\\AlexRichingsCHIMES\\output\\snapshot_500.hdf5\n",
      "\\Users\\shife\\OneDrive\\CIERA_REU\\Snapshots\\AlexRichingsCHIMES\\output\\snapshot_500.hdf5\n",
      "PartType4 has no Density\n"
     ]
    }
   ],
   "source": [
    "## load in the data from hdf5 files and put it into reader.partsDict\n",
    "for i,p in enumerate(reader.returnParts):\n",
    "    reader.decimate[p] = decimate[i]\n",
    "    reader.returnKeys[p] = ['Coordinates', 'Density','Velocities']\n",
    "    #Note: you should only try to filter on scalar values (like density).  \n",
    "    #The magnitude of the Velocities are calculated in Firefly, and you will automatically be allowed to filter on it\n",
    "    reader.addFilter[p] = [False, True, False]\n",
    "    ## tell it to do the log of density when filtering\n",
    "    reader.dolog[p] = [False, True, False]\n",
    "    \n",
    "    \n",
    "    #NOTE: all dictionaries in the \"options\" reference the swapped names (i.e., reader.names) you define above.  \n",
    "    #If you don't define reader.names, then you can use the default keys from the hdf5 files \n",
    "    #(but then you will see those hdf5 names in the Firefly GUI)\n",
    "    pp = reader.names[p]\n",
    "    ## set the initial size of the particles when the interface loads\n",
    "    reader.options['sizeMult'][pp] = 0.5\n",
    "    \n",
    "## set the default colors when the interface loads\n",
    "reader.options['color'] = {'Gas':  [1., 0.3, 0., 1.],  \n",
    "                           'Stars':[0., 1., .85, 1]} \n",
    "\n",
    "## set the camera center to be at the origin (defaults to np.mean(Coordinates) otherwise)\n",
    "##     later on we subtract out halo_center from coordinates but could instead make this halo_center\n",
    "reader.options['center'] = np.array([0., 0., 0.])\n",
    "\n",
    "## initialize filter flags and options\n",
    "reader.defineFilterKeys()\n",
    "\n",
    "## load in return keys from snapshot\n",
    "filenames_opened = reader.populate_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate the galactocentric radius, offset the coordinates by it while we're at it, then add the array to Firefly using the `addtodict` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hubble=.702\n",
    "\n",
    "## calculate the radius from the halo center\n",
    "gas_radii = np.sum(reader.partsDict['PartType0']['Coordinates']**2,axis=1)**0.5\n",
    "star_radii = np.sum(reader.partsDict['PartType4']['Coordinates']**2,axis=1)**0.5\n",
    "\n",
    "## add new radius array to the dictionary using addtodict method\n",
    "reader.addtodict(reader.partsDict,None,'PartType0','Radius',0,0,vals=gas_radii, filterFlag = True)\n",
    "reader.addtodict(reader.partsDict,None,'PartType4','Radius',0,0,vals=star_radii, filterFlag = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's convert the density to physical units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PartType0', 'PartType4'])\n"
     ]
    }
   ],
   "source": [
    "print(reader.partsDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code mass -> g , (code length)^-3 -> cm^-3 , g -> nHydrogen\n",
    "DENSITYFACT=2e43*(3.086e21)**-3/(1.67e-24)\n",
    "reader.partsDict['PartType0']['log10Density'] = reader.partsDict['PartType0']['log10Density']+np.log10(DENSITYFACT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's load necessary supplemental data to calculate the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Users\\shife\\OneDrive\\CIERA_REU\\Snapshots\\AlexRichingsCHIMES\\output\\snapshot_500.hdf5\n"
     ]
    }
   ],
   "source": [
    "## add temperature as a filtered quantity within the parts dict, but only for gas\n",
    "all_gas_temperature = np.array([])\n",
    "all_star_masses = np.array([])\n",
    "for fname in reader.loadedHDF5Files:\n",
    "    print(fname)\n",
    "    with h5py.File(fname,'r') as handle:\n",
    "        ## load necessary arrays to calculate temperature\n",
    "        gas_group = handle['PartType0']\n",
    "        InternalEnergy = np.array(gas_group['InternalEnergy'])\n",
    "        ChimesMu = np.array(gas_group['ChimesMu'])\n",
    "        \n",
    "        ## calculate the temperature and append it to total array\n",
    "        all_gas_temperature=np.append(\n",
    "            all_gas_temperature,\n",
    "            getTemperature(\n",
    "                InternalEnergy, ChimesMu)\n",
    "        )\n",
    "        \n",
    "        ## save stellar masses for vcom below\n",
    "        all_star_masses=np.append(\n",
    "            all_star_masses,\n",
    "            np.array(handle['PartType4/Masses'])\n",
    "        )\n",
    "    \n",
    "## track the Temperature array, do the log, and add it to be filtered\n",
    "reader.addtodict(reader.partsDict,None,'PartType0','Temperature',sendlog = 1, sendmag = 0,vals = all_gas_temperature, filterFlag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method addtodict in module FIREreader:\n",
      "\n",
      "addtodict(d, snap, part, dkey, sendlog, sendmag, usekey=None, mfac=1.0, vals=None, filterFlag=False) method of FIREreader.FIREreader instance\n",
      "    #adds an array to the dict for a given particle set and data file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(reader.addtodict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add more filter keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Users\\shife\\OneDrive\\CIERA_REU\\Snapshots\\AlexRichingsCHIMES\\output\\snapshot_500.hdf5\n"
     ]
    }
   ],
   "source": [
    "# open Snapshot and extract Stellar Formation Time\n",
    "stars = openSnapshot(reader.directory,reader.snapnum,4,cosmological=0,keys_to_extract=['AgeGyr'],fnames=reader.loadedHDF5Files)\n",
    "\n",
    "# add age in Myr to dict\n",
    "reader.addtodict(reader.partsDict,None,'PartType4','Stellar Age',sendlog = 0, sendmag = 0,vals = stars['AgeGyr'] * 1000, filterFlag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open Snapshot and extract chimes abundance\n",
    "abundance = openSnapshot(reader.directory,reader.snapnum,0,cosmological=0,keys_to_extract=['HIIAbundance'],fnames=reader.loadedHDF5Files)\n",
    "\n",
    "# add chimes abundance to dict\n",
    "reader.addtodict(reader.partsDict,None,'PartType0','HII Abundance',sendlog = 0, sendmag = 0,vals = abundance['HIIAbundance'], filterFlag = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now let's pre-filter certain parameters to our liking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates\n",
      "filtered\n",
      "Velocities\n",
      "filtered\n",
      "filterKeys\n",
      "doSPHrad\n",
      "Radius\n",
      "filtered\n",
      "Stellar Age\n",
      "filtered\n"
     ]
    }
   ],
   "source": [
    "# filter out stars older than 0.5 Gyr\n",
    "stars_ind = np.where(stars['AgeGyr'] < 0.5)[0]\n",
    "\n",
    "# adjust appropriate dictionary keys accordingly (i.e. density, velocity, radius, temperature, stellar age)\n",
    "for x in list(reader.partsDict['PartType4'].keys()):\n",
    "    print(x)\n",
    "    if (x not in reader.nodecimate):\n",
    "        print(\"filtered\")\n",
    "        reader.partsDict['PartType4'][x] = reader.partsDict['PartType4'][x][stars_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates\n",
      "filtered\n",
      "log10Density\n",
      "filtered\n",
      "Velocities\n",
      "filtered\n",
      "filterKeys\n",
      "doSPHrad\n",
      "Radius\n",
      "filtered\n",
      "log10Temperature\n",
      "filtered\n"
     ]
    }
   ],
   "source": [
    "# filter out gas less dense than 1 particle/cm^3\n",
    "gas_ind = np.where(reader.partsDict['PartType0']['log10Density'] > -1)[0]\n",
    "\n",
    "# adjust appropriate dictionary keys accordingly (i.e. density, velocity, radius, temperature, stellar age)\n",
    "for x in list(reader.partsDict['PartType0'].keys()):\n",
    "    print(x)\n",
    "    if (x not in reader.nodecimate):\n",
    "        print(\"filtered\")\n",
    "        reader.partsDict['PartType0'][x] = reader.partsDict['PartType0'][x][gas_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader.dataDir = \"AlexRichingsCHIMES_500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decimating and shuffling ...\n",
      "shuffling ... \n",
      "dataDir AlexRichingsCHIMES_500\n",
      "writing JSON files ...\n",
      "Gas\n",
      "Stars\n",
      "AlexRichingsCHIMES_500\\FIREdataOptions.json\n"
     ]
    }
   ],
   "source": [
    "## finish up, let's shuffle + decimate, add the GUI friendly names, and create our final JSON!\n",
    "reader.shuffle_dict()\n",
    "reader.swap_dict_names()\n",
    "reader.createJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
